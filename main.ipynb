{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9c1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from diffusers import StableDiffusion3ControlNetPipeline, SD3ControlNetModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from transformers import CLIPTextModel, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"jehanbhathena/weather-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a7781aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg')):\n",
    "            image_paths.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5345b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.cache/kagglehub/datasets/jehanbhathena/weather-dataset/versions/3/dataset/fogsmog/4357.jpg'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[3470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cd9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bw_dataset(image_paths, output_dir):\n",
    "\tclear_output()\n",
    "\tif not os.path.exists(output_dir):\n",
    "\t\tos.makedirs(output_dir)\n",
    "\tif not os.path.exists(Path(output_dir) / \"train\"):\n",
    "\t\tos.makedirs(Path(output_dir) / \"train\")\n",
    "\tif not os.path.exists(Path(output_dir) / \"train_colored\"):\n",
    "\t\tos.makedirs(Path(output_dir) / \"train_colored\")\n",
    "\tprogress_bar = tqdm(total=len(image_paths), desc=\"Creating bw images\", unit=\"image\")\n",
    "\tfor image_id in range(len(image_paths)):\n",
    "\t\ttry:\n",
    "\t\t\timage = cv2.imread(image_paths[image_id])\n",
    "\t\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\texcept Exception:\n",
    "\t\t\tprint(f\"Error reading image {image_paths[image_id]}\")\n",
    "\t\t\tprogress_bar.update(1)\n",
    "\t\t\tcontinue\n",
    "\t\tfor x in range(len(gray)):\n",
    "\t\t\tfor y in range(len(gray[x])):\n",
    "\t\t\t\tif gray[x][y] < 128:\n",
    "\t\t\t\t\tgray[x][y] = 0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tgray[x][y] = 255\n",
    "\t\tcv2.imwrite(Path(output_dir) / \"train\" / f\"img{image_id}.jpg\", gray)\n",
    "\t\tcv2.imwrite(Path(output_dir) / \"train_colored\" / f\"img{image_id}.jpg\", image)\n",
    "\t\tprogress_bar.update(1)\n",
    "\tprogress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4adc96b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caccd93fb624261bf47fbf64e978a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating bw images:   0%|          | 0/6862 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading image /root/.cache/kagglehub/datasets/jehanbhathena/weather-dataset/versions/3/dataset/fogsmog/4514.jpg\n",
      "Error reading image /root/.cache/kagglehub/datasets/jehanbhathena/weather-dataset/versions/3/dataset/snow/1187.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "create_bw_dataset(image_paths, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0226713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BWColorizationDatasetCV2(Dataset):\n",
    "    def __init__(self, bw_dir, color_dir, image_size=512):\n",
    "        self.bw_dir = bw_dir\n",
    "        self.color_dir = color_dir\n",
    "        self.image_size = image_size\n",
    "        self.bw_images = sorted(os.listdir(bw_dir))\n",
    "        self.color_images = sorted(os.listdir(color_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bw_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bw_path = os.path.join(self.bw_dir, self.bw_images[idx])\n",
    "        color_path = os.path.join(self.color_dir, self.color_images[idx])\n",
    "\n",
    "        bw_img = cv2.imread(bw_path, cv2.IMREAD_GRAYSCALE)\n",
    "        color_img = cv2.imread(color_path, cv2.IMREAD_COLOR)\n",
    "        color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bw_img = cv2.resize(bw_img, (self.image_size, self.image_size))\n",
    "        color_img = cv2.resize(color_img, (self.image_size, self.image_size))\n",
    "\n",
    "        # Normalize to [0,1]\n",
    "        bw_img = bw_img.astype(\"float32\") / 255.0\n",
    "        color_img = color_img.astype(\"float32\") / 255.0\n",
    "\n",
    "        # Convert to tensor and scale to [-1,1]\n",
    "        bw_img = torch.from_numpy(bw_img).unsqueeze(0)  # [1,H,W]\n",
    "        bw_img = bw_img * 2 - 1\n",
    "\n",
    "        color_img = torch.from_numpy(color_img).permute(2, 0, 1)  # [3,H,W]\n",
    "        color_img = color_img * 2 - 1\n",
    "\n",
    "        return bw_img, color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4b92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7ed29ed954480cbfe8fee4430786ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00c060279b84793b4b528f2f1ffb4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b926bb91c4432f95efd5a4499ec55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = BWColorizationDatasetCV2(\"dataset/train\", \"dataset/train_colored\")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2)\n",
    "\n",
    "# Load models\n",
    "controlnet = SD3ControlNetModel.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3.5-large-controlnet-canny\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda\")\n",
    "\n",
    "pipe = StableDiffusion3ControlNetPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3.5-large\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda\")\n",
    "\n",
    "pipe.enable_model_cpu_offload()  # offload to CPU when not used, save VRAM\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(controlnet.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop params\n",
    "num_epochs = 5\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * len(dataloader))\n",
    "\n",
    "controlnet.train()\n",
    "\n",
    "clear_output()\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tepoch_loss = 0\n",
    "\tepoch_progress = tqdm(total=len(dataloader), desc=\"Images\", unit=\"image\")\n",
    "\tfor bw_img, color_img in dataloader:\n",
    "\t\tbw_img = bw_img.to(\"cuda\", dtype=torch.float16)\n",
    "\t\tcolor_img = color_img.to(\"cuda\", dtype=torch.float16)\n",
    "\n",
    "\t\t# 1. Encode color_img to latents using pipe.vae\n",
    "\t\tlatents = pipe.vae.encode(color_img).latent_dist.sample() * 0.18215  # scale latent\n",
    "\t\tlatents = latents.to(torch.float16)\n",
    "\n",
    "\t\t# 2. Sample noise and timesteps\n",
    "\t\tnoise = torch.randn_like(latents)\n",
    "\t\ttimesteps = torch.randint(0, pipe.scheduler.config.num_train_timesteps, (latents.shape[0],), device=latents.device)\n",
    "\n",
    "\t\t# 3. Add noise to latents (forward diffusion)\n",
    "\t\tnoisy_latents = pipe.scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "\t\t# 4. Get conditioning image (BW)\n",
    "\t\tcontrol = bw_img\n",
    "\n",
    "\t\t# 5. Get text embeddings (you can customize prompt, here empty string)\n",
    "\t\tprompt = [\"\"] * latents.shape[0]\n",
    "\t\ttext_input = pipe.tokenizer(prompt, padding=\"max_length\", max_length=pipe.tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
    "\t\ttext_embeddings = pipe.text_encoder(text_input.input_ids.to(\"cuda\"))[0]\n",
    "\n",
    "\t\t# 6. Forward pass: UNet predicts noise residual conditioned on text and controlnet conditioning image\n",
    "\t\tnoise_pred = pipe.unet(noisy_latents, timesteps, encoder_hidden_states=text_embeddings, controlnet_cond=control).sample\n",
    "\n",
    "\t\t# 7. Compute loss = MSE between predicted noise and true noise\n",
    "\t\tloss = torch.nn.functional.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tscheduler.step()\n",
    "\n",
    "\t\tepoch_loss += loss.item()\n",
    "        \n",
    "\t\tepoch_progress.update(1)\n",
    "\t\n",
    "\tepoch_progress.close()\n",
    "\n",
    "\tprint(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss / len(dataloader):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.controlnet.save_pretrained(\"qworks-bw-colorizer-controlnet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
